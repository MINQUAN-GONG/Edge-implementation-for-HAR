{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "16b149ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import scipy.stats as stats\n",
    "import time\n",
    "import tensorflow as tf\n",
    "from matplotlib import pyplot as plt\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "from tensorflow.keras import Sequential\n",
    "from tensorflow.keras.layers import Flatten, Dense, BatchNormalization, Dropout\n",
    "from tensorflow.keras.layers import Conv1D, MaxPool1D"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "64ff523d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#File Importing (total 48 files)\n",
    "def load_file(path,act):\n",
    "    file = pd.read_hdf(path,key=act)\n",
    "    #s_train.append(file)\n",
    "    return file\n",
    "\n",
    "# s1-s15:walk\n",
    "s1 = load_file('wrist_ppg_data/s15_all_signals.hdf5','walk')\n",
    "s2 = load_file('wrist_ppg_data/s16_all_signals.hdf5','walk')\n",
    "s3 = load_file('wrist_ppg_data/s17_all_signals.hdf5','walk')\n",
    "s4 = load_file('wrist_ppg_data/s21_all_signals.hdf5','walk')\n",
    "s5 = load_file('wrist_ppg_data/s22_all_signals.hdf5','walk')\n",
    "s6 = load_file('wrist_ppg_data/s23_all_signals.hdf5','walk')\n",
    "s7 = load_file('wrist_ppg_data/s24_all_signals.hdf5','walk')\n",
    "s8 = load_file('wrist_ppg_data/s25_all_signals.hdf5','walk')\n",
    "s9 = load_file('wrist_ppg_data/s26_all_signals.hdf5','walk')\n",
    "s10 = load_file('wrist_ppg_data/s27_all_signals.hdf5','walk')\n",
    "s11 = load_file('wrist_ppg_data/s28_all_signals.hdf5','walk')\n",
    "s12 = load_file('wrist_ppg_data/s30_all_signals.hdf5','walk')\n",
    "s13 = load_file('wrist_ppg_data/s31_all_signals.hdf5','walk')\n",
    "s14 = load_file('wrist_ppg_data/s32_all_signals.hdf5','walk')\n",
    "s15 = load_file('wrist_ppg_data/s34_all_signals.hdf5','walk')\n",
    "# s16-s19:run\n",
    "s16 = load_file('wrist_ppg_data/s15_all_signals.hdf5','run')\n",
    "s17 = load_file('wrist_ppg_data/s24_all_signals.hdf5','run')\n",
    "s18 = load_file('wrist_ppg_data/s28_all_signals.hdf5','run')\n",
    "s19 = load_file('wrist_ppg_data/s34_all_signals.hdf5','run')\n",
    "# s20-s34:lrb\n",
    "s20 = load_file('wrist_ppg_data/s15_all_signals.hdf5','lrb')\n",
    "s21 = load_file('wrist_ppg_data/s16_all_signals.hdf5','lrb')\n",
    "s22 = load_file('wrist_ppg_data/s17_all_signals.hdf5','lrb')\n",
    "s23 = load_file('wrist_ppg_data/s21_all_signals.hdf5','lrb')\n",
    "s24 = load_file('wrist_ppg_data/s22_all_signals.hdf5','lrb')\n",
    "s25 = load_file('wrist_ppg_data/s23_all_signals.hdf5','lrb')\n",
    "s26 = load_file('wrist_ppg_data/s24_all_signals.hdf5','lrb')\n",
    "s27 = load_file('wrist_ppg_data/s25_all_signals.hdf5','lrb')\n",
    "s28 = load_file('wrist_ppg_data/s26_all_signals.hdf5','lrb')\n",
    "s29 = load_file('wrist_ppg_data/s27_all_signals.hdf5','lrb')\n",
    "s30 = load_file('wrist_ppg_data/s28_all_signals.hdf5','lrb')\n",
    "s31 = load_file('wrist_ppg_data/s30_all_signals.hdf5','lrb')\n",
    "s32 = load_file('wrist_ppg_data/s31_all_signals.hdf5','lrb')\n",
    "s33 = load_file('wrist_ppg_data/s32_all_signals.hdf5','lrb')\n",
    "s34 = load_file('wrist_ppg_data/s34_all_signals.hdf5','lrb')\n",
    "# s35-s48:hrb\n",
    "s35 = load_file('wrist_ppg_data/s15_all_signals.hdf5','hrb')\n",
    "s36 = load_file('wrist_ppg_data/s16_all_signals.hdf5','hrb')\n",
    "s37 = load_file('wrist_ppg_data/s17_all_signals.hdf5','hrb')\n",
    "s38 = load_file('wrist_ppg_data/s21_all_signals.hdf5','hrb')\n",
    "s39 = load_file('wrist_ppg_data/s23_all_signals.hdf5','hrb')\n",
    "s40 = load_file('wrist_ppg_data/s24_all_signals.hdf5','hrb')\n",
    "s41 = load_file('wrist_ppg_data/s25_all_signals.hdf5','hrb')\n",
    "s42 = load_file('wrist_ppg_data/s26_all_signals.hdf5','hrb')\n",
    "s43 = load_file('wrist_ppg_data/s27_all_signals.hdf5','hrb')\n",
    "s44 = load_file('wrist_ppg_data/s28_all_signals.hdf5','hrb')\n",
    "s45 = load_file('wrist_ppg_data/s30_all_signals.hdf5','hrb')\n",
    "s46 = load_file('wrist_ppg_data/s31_all_signals.hdf5','hrb')\n",
    "s47 = load_file('wrist_ppg_data/s32_all_signals.hdf5','hrb')\n",
    "s48 = load_file('wrist_ppg_data/s34_all_signals.hdf5','hrb')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0866ebc7",
   "metadata": {},
   "outputs": [
    {
     "ename": "MemoryError",
     "evalue": "Unable to allocate 694. MiB for an array with shape (16, 5685320) and data type float64",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mMemoryError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-3-b90439c87dd2>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     17\u001b[0m \u001b[0md_hrb\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mconcat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mconcat_file\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m35\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m49\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     18\u001b[0m \u001b[0md_hrb\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'label'\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m3\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 19\u001b[1;33m \u001b[0mdata\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mconcat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0md_walk\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0md_run\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0md_lrb\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0md_hrb\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     20\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtype\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     21\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\Anoconda_setup\\envs\\tf\\lib\\site-packages\\pandas\\core\\reshape\\concat.py\u001b[0m in \u001b[0;36mconcat\u001b[1;34m(objs, axis, join, ignore_index, keys, levels, names, verify_integrity, sort, copy)\u001b[0m\n\u001b[0;32m    285\u001b[0m     )\n\u001b[0;32m    286\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 287\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0mop\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_result\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    288\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    289\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\Anoconda_setup\\envs\\tf\\lib\\site-packages\\pandas\\core\\reshape\\concat.py\u001b[0m in \u001b[0;36mget_result\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    501\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    502\u001b[0m             new_data = concatenate_block_managers(\n\u001b[1;32m--> 503\u001b[1;33m                 \u001b[0mmgrs_indexers\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnew_axes\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mconcat_axis\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbm_axis\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcopy\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    504\u001b[0m             )\n\u001b[0;32m    505\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcopy\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\Anoconda_setup\\envs\\tf\\lib\\site-packages\\pandas\\core\\internals\\concat.py\u001b[0m in \u001b[0;36mconcatenate_block_managers\u001b[1;34m(mgrs_indexers, axes, concat_axis, copy)\u001b[0m\n\u001b[0;32m     77\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     78\u001b[0m             b = make_block(\n\u001b[1;32m---> 79\u001b[1;33m                 \u001b[0m_concatenate_join_units\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mjoin_units\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mconcat_axis\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mcopy\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     80\u001b[0m                 \u001b[0mplacement\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mplacement\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     81\u001b[0m             )\n",
      "\u001b[1;32mD:\\Anoconda_setup\\envs\\tf\\lib\\site-packages\\pandas\\core\\internals\\concat.py\u001b[0m in \u001b[0;36m_concatenate_join_units\u001b[1;34m(join_units, concat_axis, copy)\u001b[0m\n\u001b[0;32m    344\u001b[0m             \u001b[0mconcat_values\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0matleast_2d\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mconcat_values\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    345\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 346\u001b[1;33m         \u001b[0mconcat_values\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mconcat_compat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mto_concat\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mconcat_axis\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    347\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    348\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mconcat_values\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\Anoconda_setup\\envs\\tf\\lib\\site-packages\\pandas\\core\\dtypes\\concat.py\u001b[0m in \u001b[0;36mconcat_compat\u001b[1;34m(to_concat, axis)\u001b[0m\n\u001b[0;32m    178\u001b[0m                 \u001b[0mto_concat\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"object\"\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mto_concat\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    179\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 180\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mconcatenate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mto_concat\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0maxis\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    181\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    182\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<__array_function__ internals>\u001b[0m in \u001b[0;36mconcatenate\u001b[1;34m(*args, **kwargs)\u001b[0m\n",
      "\u001b[1;31mMemoryError\u001b[0m: Unable to allocate 694. MiB for an array with shape (16, 5685320) and data type float64"
     ]
    }
   ],
   "source": [
    "# concat data and add label column\n",
    "def concat_file(startn,endn):\n",
    "    frame = []\n",
    "    for i in range(startn,endn):\n",
    "        ss = 's' + str(i) #represent s1,s2,...,s48\n",
    "        s_con = eval(ss) #convert to pandas dataframe\n",
    "        frame.append(s_con) #saved in a list\n",
    "    return frame\n",
    "\n",
    "# add label\n",
    "d_walk = pd.concat(concat_file(1,16))\n",
    "d_walk['label'] = 0\n",
    "d_run = pd.concat(concat_file(16,20))\n",
    "d_run['label'] = 1\n",
    "d_lrb = pd.concat(concat_file(20,35))\n",
    "d_lrb['label'] = 2\n",
    "d_hrb = pd.concat(concat_file(35,49))\n",
    "d_hrb['label'] = 3\n",
    "data = pd.concat([d_walk,d_run,d_lrb,d_hrb])\n",
    "print(type(data))\n",
    "print(data.shape)\n",
    "#print(data.head)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bdc565bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "#delete useless information\n",
    "data = data.drop(['events','chest_ecg','chest_accelerometer_x','chest_accelerometer_y','chest_accelerometer_z','wrist_right_hr','ankle_left_ppg','ankle_left_accelerometer_x','ankle_left_accelerometer_y','ankle_left_accelerometer_z','ankle_right_ppg','ankle_right_accelerometer_x','ankle_right_accelerometer_y','ankle_right_accelerometer_z'],axis = 1).copy()\n",
    "data.head(5776993)\n",
    "data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "465595ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "min_activity = data['label'].value_counts().min()\n",
    "data['label'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7958af4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Scale Standardization\n",
    "xdata = data[['wrist_left_ppg','wrist_left_accelerometer_x','wrist_left_accelerometer_y','wrist_left_accelerometer_z']]\n",
    "min_max_scaler = MinMaxScaler(feature_range=(-1,1)) #scale to the range (-1,1)\n",
    "X = min_max_scaler.fit_transform(xdata)\n",
    "print(type(X))\n",
    "print(X.shape)\n",
    "print(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f41ca81",
   "metadata": {},
   "outputs": [],
   "source": [
    "#combine scaled data\n",
    "scaled_data = pd.DataFrame(data = X, columns = ['ppg','accx','accy','accz'])\n",
    "scaled_data['label'] = data['label'].values\n",
    "print(scaled_data.shape)\n",
    "print(type(scaled_data))\n",
    "print(scaled_data.head(5776992))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ed620d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sliding Window Segment\n",
    "fs = 200\n",
    "frame_size = fs * 8 # one frame consists of 8 seconds\n",
    "hop_size = fs * 1  #87.5% overlap\n",
    "\n",
    "def get_frames(x_train, frame_size, hop_size):\n",
    "    N_FEATURES = 4\n",
    "    frames = []\n",
    "    labels = []\n",
    "    \n",
    "    for i in range(0, len(x_train) - frame_size, hop_size):\n",
    "        ppg = x_train['ppg'].values[i:i+frame_size]\n",
    "        x = x_train['accx'].values[i:i+frame_size]\n",
    "        y = x_train['accy'].values[i:i+frame_size]\n",
    "        z = x_train['accz'].values[i:i+frame_size]\n",
    "        \n",
    "        # retrieve the most often used label in this segment\n",
    "        label = stats.mode(x_train['label'][i:i+frame_size])[0][0]\n",
    "        frames.append([ppg,x, y, z])\n",
    "        labels.append(label)\n",
    "    \n",
    "    # bring the segment into a better shape\n",
    "    frames = np.asarray(frames).reshape(-1, frame_size, N_FEATURES)\n",
    "    labels = np.asarray(labels)\n",
    "    return frames, labels\n",
    "\n",
    "X,y = get_frames(scaled_data, frame_size, hop_size)\n",
    "print(X.shape,y.shape) #(5776992*features)/(frame_size*2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "adb9c4e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# one-hot convertion\n",
    "y = tf.keras.utils.to_categorical(y)\n",
    "print(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b054295",
   "metadata": {},
   "outputs": [],
   "source": [
    "# split training and testing dataset\n",
    "X_train,X_test,y_train,y_test = train_test_split(X,y,test_size=0.3,random_state=0,stratify=y)\n",
    "print(X_train.shape,X_test.shape,y_train.shape,y_test.shape)\n",
    "print(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b77fc2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Convert to Float32\n",
    "X_test = X_test.astype(np.float32)\n",
    "y_test = y_test.astype(np.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c02d467",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test = np.argmax(y_test, axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79830665",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Load the TFLite model and allocate tensors\n",
    "interpreter = tf.lite.Interpreter(model_path=\"tflite_model_quant_fullint.tflite\")\n",
    "interpreter.allocate_tensors()\n",
    "\n",
    "# Get input and output tensors\n",
    "input_details = interpreter.get_input_details()\n",
    "output_details = interpreter.get_output_details()\n",
    "\n",
    "#Run Interpreter in for loop for every test data entry \n",
    "accuracy_count = 0\n",
    "#Comuting Time\n",
    "time1 = time.time()\n",
    "for i in range(X_test.shape[0]):\n",
    "    input_shape = input_details[0]['shape']\n",
    "    interpreter.set_tensor(input_details[0]['index'], X_test[i:i+1,:,:])#include type\n",
    "    interpreter.invoke()\n",
    "    output_data = interpreter.get_tensor(output_details[0]['index'])#array of (1,4)\n",
    "    predict_label = np.argmax(output_data) #predicted label from interpreter\n",
    "    #print(i,output_data)\n",
    "    #check if prediction is correct\n",
    "    if predict_label == y_test[i]:\n",
    "        accuracy_count += 1\n",
    "        #print(accuracy_count)\n",
    "\n",
    "#Overall accuracy for entire test \n",
    "accuracy = accuracy_count * 1.0 / y_test.size \n",
    "print(accuracy_count)\n",
    "print('TensorFlow Lite model accuracy: %.4f' % accuracy)\n",
    "time2 = time.time()\n",
    "print('Consuming time is %.4f' % (time2-time1))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
