{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "16b149ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import scipy.stats as stats\n",
    "import time\n",
    "import tensorflow as tf\n",
    "from matplotlib import pyplot as plt\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "from tensorflow.keras import Sequential\n",
    "from tensorflow.keras.layers import Flatten, Dense, BatchNormalization, Dropout\n",
    "from tensorflow.keras.layers import Conv1D, MaxPool1D"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "64ff523d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#File Importing (total 48 files)\n",
    "def load_file(path,act):\n",
    "    file = pd.read_hdf(path,key=act)\n",
    "    #s_train.append(file)\n",
    "    return file\n",
    "\n",
    "# s1-s15:walk\n",
    "s1 = load_file('wrist_ppg_data/s15_all_signals.hdf5','walk')\n",
    "s2 = load_file('wrist_ppg_data/s16_all_signals.hdf5','walk')\n",
    "s3 = load_file('wrist_ppg_data/s17_all_signals.hdf5','walk')\n",
    "s4 = load_file('wrist_ppg_data/s21_all_signals.hdf5','walk')\n",
    "s5 = load_file('wrist_ppg_data/s22_all_signals.hdf5','walk')\n",
    "s6 = load_file('wrist_ppg_data/s23_all_signals.hdf5','walk')\n",
    "s7 = load_file('wrist_ppg_data/s24_all_signals.hdf5','walk')\n",
    "s8 = load_file('wrist_ppg_data/s25_all_signals.hdf5','walk')\n",
    "s9 = load_file('wrist_ppg_data/s26_all_signals.hdf5','walk')\n",
    "s10 = load_file('wrist_ppg_data/s27_all_signals.hdf5','walk')\n",
    "s11 = load_file('wrist_ppg_data/s28_all_signals.hdf5','walk')\n",
    "s12 = load_file('wrist_ppg_data/s30_all_signals.hdf5','walk')\n",
    "s13 = load_file('wrist_ppg_data/s31_all_signals.hdf5','walk')\n",
    "s14 = load_file('wrist_ppg_data/s32_all_signals.hdf5','walk')\n",
    "s15 = load_file('wrist_ppg_data/s34_all_signals.hdf5','walk')\n",
    "# s16-s19:run\n",
    "s16 = load_file('wrist_ppg_data/s15_all_signals.hdf5','run')\n",
    "s17 = load_file('wrist_ppg_data/s24_all_signals.hdf5','run')\n",
    "s18 = load_file('wrist_ppg_data/s28_all_signals.hdf5','run')\n",
    "s19 = load_file('wrist_ppg_data/s34_all_signals.hdf5','run')\n",
    "# s20-s34:lrb\n",
    "s20 = load_file('wrist_ppg_data/s15_all_signals.hdf5','lrb')\n",
    "s21 = load_file('wrist_ppg_data/s16_all_signals.hdf5','lrb')\n",
    "s22 = load_file('wrist_ppg_data/s17_all_signals.hdf5','lrb')\n",
    "s23 = load_file('wrist_ppg_data/s21_all_signals.hdf5','lrb')\n",
    "s24 = load_file('wrist_ppg_data/s22_all_signals.hdf5','lrb')\n",
    "s25 = load_file('wrist_ppg_data/s23_all_signals.hdf5','lrb')\n",
    "s26 = load_file('wrist_ppg_data/s24_all_signals.hdf5','lrb')\n",
    "s27 = load_file('wrist_ppg_data/s25_all_signals.hdf5','lrb')\n",
    "s28 = load_file('wrist_ppg_data/s26_all_signals.hdf5','lrb')\n",
    "s29 = load_file('wrist_ppg_data/s27_all_signals.hdf5','lrb')\n",
    "s30 = load_file('wrist_ppg_data/s28_all_signals.hdf5','lrb')\n",
    "s31 = load_file('wrist_ppg_data/s30_all_signals.hdf5','lrb')\n",
    "s32 = load_file('wrist_ppg_data/s31_all_signals.hdf5','lrb')\n",
    "s33 = load_file('wrist_ppg_data/s32_all_signals.hdf5','lrb')\n",
    "s34 = load_file('wrist_ppg_data/s34_all_signals.hdf5','lrb')\n",
    "# s35-s48:hrb\n",
    "s35 = load_file('wrist_ppg_data/s15_all_signals.hdf5','hrb')\n",
    "s36 = load_file('wrist_ppg_data/s16_all_signals.hdf5','hrb')\n",
    "s37 = load_file('wrist_ppg_data/s17_all_signals.hdf5','hrb')\n",
    "s38 = load_file('wrist_ppg_data/s21_all_signals.hdf5','hrb')\n",
    "s39 = load_file('wrist_ppg_data/s23_all_signals.hdf5','hrb')\n",
    "s40 = load_file('wrist_ppg_data/s24_all_signals.hdf5','hrb')\n",
    "s41 = load_file('wrist_ppg_data/s25_all_signals.hdf5','hrb')\n",
    "s42 = load_file('wrist_ppg_data/s26_all_signals.hdf5','hrb')\n",
    "s43 = load_file('wrist_ppg_data/s27_all_signals.hdf5','hrb')\n",
    "s44 = load_file('wrist_ppg_data/s28_all_signals.hdf5','hrb')\n",
    "s45 = load_file('wrist_ppg_data/s30_all_signals.hdf5','hrb')\n",
    "s46 = load_file('wrist_ppg_data/s31_all_signals.hdf5','hrb')\n",
    "s47 = load_file('wrist_ppg_data/s32_all_signals.hdf5','hrb')\n",
    "s48 = load_file('wrist_ppg_data/s34_all_signals.hdf5','hrb')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0866ebc7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "(5685320, 19)\n"
     ]
    }
   ],
   "source": [
    "# concat data and add label column\n",
    "def concat_file(startn,endn):\n",
    "    frame = []\n",
    "    for i in range(startn,endn):\n",
    "        ss = 's' + str(i) #represent s1,s2,...,s48\n",
    "        s_con = eval(ss) #convert to pandas dataframe\n",
    "        frame.append(s_con) #saved in a list\n",
    "    return frame\n",
    "\n",
    "# add label\n",
    "d_walk = pd.concat(concat_file(1,16))\n",
    "d_walk['label'] = 0\n",
    "d_run = pd.concat(concat_file(16,20))\n",
    "d_run['label'] = 1\n",
    "d_lrb = pd.concat(concat_file(20,35))\n",
    "d_lrb['label'] = 2\n",
    "d_hrb = pd.concat(concat_file(35,49))\n",
    "d_hrb['label'] = 3\n",
    "data = pd.concat([d_walk,d_run,d_lrb,d_hrb])\n",
    "print(type(data))\n",
    "print(data.shape)\n",
    "#print(data.head)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "bdc565bb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Float64Index: 5685320 entries, 0.0 to 601.215\n",
      "Data columns (total 5 columns):\n",
      " #   Column                      Dtype  \n",
      "---  ------                      -----  \n",
      " 0   wrist_left_ppg              float64\n",
      " 1   wrist_left_accelerometer_x  float64\n",
      " 2   wrist_left_accelerometer_y  float64\n",
      " 3   wrist_left_accelerometer_z  float64\n",
      " 4   label                       int64  \n",
      "dtypes: float64(4), int64(1)\n",
      "memory usage: 260.3 MB\n"
     ]
    }
   ],
   "source": [
    "#delete useless information\n",
    "data = data.drop(['events','chest_ecg','chest_accelerometer_x','chest_accelerometer_y','chest_accelerometer_z','wrist_right_hr','ankle_left_ppg','ankle_left_accelerometer_x','ankle_left_accelerometer_y','ankle_left_accelerometer_z','ankle_right_ppg','ankle_right_accelerometer_x','ankle_right_accelerometer_y','ankle_right_accelerometer_z'],axis = 1).copy()\n",
    "data.head(5776993)\n",
    "data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "465595ec",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2    1787775\n",
       "0    1775700\n",
       "3    1656919\n",
       "1     464926\n",
       "Name: label, dtype: int64"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "min_activity = data['label'].value_counts().min()\n",
    "data['label'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "7958af4a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'numpy.ndarray'>\n",
      "(5685320, 4)\n"
     ]
    }
   ],
   "source": [
    "# Scale Standardization\n",
    "xdata = data[['wrist_left_ppg','wrist_left_accelerometer_x','wrist_left_accelerometer_y','wrist_left_accelerometer_z']]\n",
    "min_max_scaler = MinMaxScaler(feature_range=(-1,1)) #scale to the range (-1,1)\n",
    "X = min_max_scaler.fit_transform(xdata)\n",
    "print(type(X))\n",
    "print(X.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "8f41ca81",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(5685320, 5)\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "              ppg      accx      accy      accz  label\n",
      "0        0.091756 -0.159367  0.393531  0.061759      0\n",
      "1        0.091241 -0.158706  0.392370  0.059931      0\n",
      "2        0.090738 -0.158131  0.391169  0.058367      0\n",
      "3        0.090222 -0.157813  0.390377  0.057170      0\n",
      "4        0.089678 -0.157887  0.390376  0.056384      0\n",
      "...           ...       ...       ...       ...    ...\n",
      "5685315 -0.170856  0.147863 -0.406727 -0.058306      3\n",
      "5685316 -0.181045  0.142977 -0.404441 -0.064955      3\n",
      "5685317 -0.192560  0.132919 -0.403442 -0.072393      3\n",
      "5685318 -0.204983  0.118292 -0.402980 -0.080206      3\n",
      "5685319 -0.218243  0.101060 -0.403041 -0.087830      3\n",
      "\n",
      "[5685320 rows x 5 columns]\n"
     ]
    }
   ],
   "source": [
    "#combine scaled data\n",
    "scaled_data = pd.DataFrame(data = X, columns = ['ppg','accx','accy','accz'])\n",
    "scaled_data['label'] = data['label'].values\n",
    "print(scaled_data.shape)\n",
    "print(type(scaled_data))\n",
    "print(scaled_data.head(5776992))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "2ed620d4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(28419, 1600, 4) (28419,)\n",
      "[0 0 0 ... 3 3 3]\n"
     ]
    }
   ],
   "source": [
    "# Sliding Window Segment\n",
    "fs = 200\n",
    "frame_size = fs * 8 # one frame consists of 2 seconds\n",
    "hop_size = fs * 1  #75% overlap\n",
    "\n",
    "def get_frames(x_train, frame_size, hop_size):\n",
    "    N_FEATURES = 4\n",
    "    frames = []\n",
    "    labels = []\n",
    "    \n",
    "    for i in range(0, len(x_train) - frame_size, hop_size):\n",
    "        ppg = x_train['ppg'].values[i:i+frame_size]\n",
    "        x = x_train['accx'].values[i:i+frame_size]\n",
    "        y = x_train['accy'].values[i:i+frame_size]\n",
    "        z = x_train['accz'].values[i:i+frame_size]\n",
    "        \n",
    "        # retrieve the most often used label in this segment\n",
    "        label = stats.mode(x_train['label'][i:i+frame_size])[0][0]\n",
    "        frames.append([ppg,x, y, z])\n",
    "        labels.append(label)\n",
    "    \n",
    "    # bring the segment into a better shape\n",
    "    frames = np.asarray(frames).reshape(-1, frame_size, N_FEATURES)\n",
    "    labels = np.asarray(labels)\n",
    "    return frames, labels\n",
    "\n",
    "X,y = get_frames(scaled_data, frame_size, hop_size)\n",
    "print(X.shape,y.shape) #(5776992*features)/(frame_size*2)\n",
    "print(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c97c7609",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'numpy.ndarray'>\n",
      "(28419, 4)\n",
      "[[1. 0. 0. 0.]\n",
      " [1. 0. 0. 0.]\n",
      " [1. 0. 0. 0.]\n",
      " ...\n",
      " [0. 0. 0. 1.]\n",
      " [0. 0. 0. 1.]\n",
      " [0. 0. 0. 1.]]\n"
     ]
    }
   ],
   "source": [
    "# one-hot convertion\n",
    "y = tf.keras.utils.to_categorical(y)\n",
    "print(type(y))\n",
    "print(y.shape)\n",
    "print(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "3b054295",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(19893, 1600, 4) (8526, 1600, 4) (19893, 4) (8526, 4)\n",
      "[[0. 0. 1. 0.]\n",
      " [0. 0. 1. 0.]\n",
      " [0. 0. 0. 1.]\n",
      " ...\n",
      " [0. 0. 0. 1.]\n",
      " [0. 0. 0. 1.]\n",
      " [0. 0. 0. 1.]]\n"
     ]
    }
   ],
   "source": [
    "# split training and testing dataset\n",
    "X_train,X_test,y_train,y_test = train_test_split(X,y,test_size=0.3,random_state=0,stratify=y)\n",
    "print(X_train.shape,X_test.shape,y_train.shape,y_test.shape)\n",
    "print(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "862a4b3a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv1d (Conv1D)              (None, 1598, 8)           104       \n",
      "_________________________________________________________________\n",
      "max_pooling1d (MaxPooling1D) (None, 532, 8)            0         \n",
      "_________________________________________________________________\n",
      "conv1d_1 (Conv1D)            (None, 530, 16)           400       \n",
      "_________________________________________________________________\n",
      "max_pooling1d_1 (MaxPooling1 (None, 265, 16)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_2 (Conv1D)            (None, 263, 32)           1568      \n",
      "_________________________________________________________________\n",
      "max_pooling1d_2 (MaxPooling1 (None, 131, 32)           0         \n",
      "_________________________________________________________________\n",
      "dropout (Dropout)            (None, 131, 32)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_3 (Conv1D)            (None, 129, 64)           6208      \n",
      "_________________________________________________________________\n",
      "max_pooling1d_3 (MaxPooling1 (None, 64, 64)            0         \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 64, 64)            0         \n",
      "_________________________________________________________________\n",
      "conv1d_4 (Conv1D)            (None, 62, 128)           24704     \n",
      "_________________________________________________________________\n",
      "max_pooling1d_4 (MaxPooling1 (None, 31, 128)           0         \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 31, 128)           0         \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            (None, 3968)              0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 128)               508032    \n",
      "_________________________________________________________________\n",
      "dropout_3 (Dropout)          (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 4)                 516       \n",
      "=================================================================\n",
      "Total params: 541,532\n",
      "Trainable params: 541,532\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "#Load Pre-Trained Model\n",
    "model = tf.keras.models.load_model('Saved_models/CNN_model')\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "5b77fc2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3D array convertion\n",
    "X_train = X_test.astype(np.float32)\n",
    "X_test = X_test.astype(np.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "3b319f28",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "134/134 [==============================] - 3s 18ms/step - loss: 0.0888 - accuracy: 0.9745\n",
      "Model Accuracy: 97.45%\n"
     ]
    }
   ],
   "source": [
    "test_loss, test_acc = model.evaluate(X_test, y_test, batch_size = 64)\n",
    "print('Model Accuracy: {:.2f}%'.format(100*test_acc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "dee3faf4",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Convert to TF Lite Model\n",
    "converter = tf.lite.TFLiteConverter.from_saved_model('Saved_models/CNN_model')\n",
    "converter.experimental_new_quantizer = True\n",
    "#Dynamic Range Quatization\n",
    "#converter.optimizations = [tf.lite.Optimize.DEFAULT]\n",
    "#tflite_model = converter.convert()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "ca98c492",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Full Integer Quantization\n",
    "def representative_data_gen():\n",
    "  for input_value in tf.data.Dataset.from_tensor_slices(X_train).batch(1).take(100):\n",
    "    # Model has only one input so each data point has one element.\n",
    "    yield [input_value]\n",
    "\n",
    "converter.optimizations = [tf.lite.Optimize.DEFAULT]\n",
    "converter.representative_dataset = representative_data_gen\n",
    "tflite_model_quant_fullint = converter.convert()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "8de16596",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "input:  <class 'numpy.float32'>\n",
      "output:  <class 'numpy.float32'>\n"
     ]
    }
   ],
   "source": [
    "#partial fullint model with IO 32 bit\n",
    "#Type of IO\n",
    "interpreter = tf.lite.Interpreter(model_content=tflite_model_quant_fullint)\n",
    "input_type = interpreter.get_input_details()[0]['dtype']\n",
    "print('input: ', input_type)\n",
    "output_type = interpreter.get_output_details()[0]['dtype']\n",
    "print('output: ', output_type)\n",
    "# Save the model.\n",
    "with tf.io.gfile.GFile('tflite_model_quant_fullint.tflite','wb') as f:\n",
    "    f.write(tflite_model_quant_fullint)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "34eb93de",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:For model inputs containing unsupported operations which cannot be quantized, the `inference_input_type` attribute will default to the original type.\n"
     ]
    }
   ],
   "source": [
    "#Full Integer Quantization with IO 8bit\n",
    "def representative_data_gen():\n",
    "  for input_value in tf.data.Dataset.from_tensor_slices(X_train).batch(1).take(100):\n",
    "    # Model has only one input so each data point has one element.\n",
    "    yield [input_value]\n",
    "\n",
    "converter.optimizations = [tf.lite.Optimize.DEFAULT]\n",
    "converter.representative_dataset = representative_data_gen\n",
    "converter.target_spec.supported_ops = [tf.lite.OpsSet.TFLITE_BUILTINS_INT8]\n",
    "# Set the input and output tensors to uint8 (APIs added in r2.3)\n",
    "converter.inference_input_type = tf.uint8\n",
    "converter.inference_output_type = tf.uint8\n",
    "tflite_model_quant_uint8 = converter.convert()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "5f3ba8b5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "input:  <class 'numpy.uint8'>\n",
      "output:  <class 'numpy.uint8'>\n"
     ]
    }
   ],
   "source": [
    "#Type of IO\n",
    "interpreter = tf.lite.Interpreter(model_content=tflite_model_quant_uint8)\n",
    "input_type = interpreter.get_input_details()[0]['dtype']\n",
    "print('input: ', input_type)\n",
    "output_type = interpreter.get_output_details()[0]['dtype']\n",
    "print('output: ', output_type)\n",
    "# Save the model.\n",
    "with tf.io.gfile.GFile('tflite_model_quant_uint8.tflite','wb') as f:\n",
    "    f.write(tflite_model_quant_uint8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "f536f8f2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad7ea268",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
